---
title: 'SP''21 K579: Homework 1'
author: 'Jesus Santillan Minila'
output:
  pdf_document: default
  html_document:
    df_print: paged
  word_document: default
---

### Download "breast_cancer.csv" data file from Canvas. Make sure you read the description of Question 6 (in HW1 file) carefully before working on this part.

### Import the data into R as "cancer"

```{r}

library(caret)
library(e1071)
library(rpart)
library(rpart.plot)
library(dplyr)
library(class)
library(pROC)
library(funModeling)

cancer <-read.csv("breast_cancer.csv")

```


### After you import the data, we need to convert "Class" variable into a factor, so that R treats it as a categorical variable, instead of a numeric variable. Run the following line of code

```{r}

cancer$Class <- as.factor(cancer$Class)

```

### 1. Split the dataset into 80% training and 20% testing
```{r}

train_rows <-createDataPartition(y = cancer$Class,p = 0.80, list = FALSE)

```


### 2. Build a decision tree model
```{r}
cancer_train <- cancer[train_rows,]
cancer_test <- cancer[-train_rows,]

tree <- rpart(Class ~ .,
              data = cancer_train, 
              method = "class", 
              parms = list(split = "information"))

pred_tree <- predict(tree,cancer_test, type = "class")

```


### 3. Plot the tree, and then answer the following questions:
```{r}

prp(tree, varlen=0)

``` 

    - 3.1. How many decision nodes are there in your tree?
    5 nodes
    
    - 3.2. Pick one decision rule from your tree and interpret it
    If uniformity of cell is smaller than 3 and bare nuclei is smaller than 3, it is a benign tumor



### 4. Evaluate the performance of your tree. Specifically, report the following metrics: (1) confusion matrix; (2) accuracy; (3) precision, recall, f-measure for "malignant" class; (4) AUC for "malignant" class
```{r}

pred_tree <- predict(tree,cancer_test, type = "class")

confusionMatrix(pred_tree, as.factor(cancer_test[,10]), mode = "prec_recall")

pred_tree_prob <- predict(tree, cancer_test, type = "prob")

cancer_test_roc_tree <-cancer_test %>%
  mutate(prob = pred_tree_prob[,1]) %>%
  arrange(desc(Class))%>%
  mutate(Class_malignant = ifelse(Class == 4,1,0))

roc_tree <- roc(response = cancer_test_roc_tree$Class_malignant,
              predictor = cancer_test_roc_tree$prob)

auc_tree <- auc(roc_tree)
auc_tree

```



### 5. Now, let's consider using K-NN to do the classification. Is there any need to normalize the data? Why or why not? If you think normalization is needed, write your code below to do so. Feel free to re-use code from the in-class exercise. If you think normalization is not necessary, explain why and you do not need to write any code.
```{r}


normalize <- function(x){
    return((x-min(x))/(max(x)-min(x)))
    }

cancer_normalized <- cancer %>% mutate_at(1:9,normalize)

cancer_normalized_train <- cancer_normalized[train_rows,]
cancer_normalized_test <- cancer_normalized[-train_rows,]

```


### 6. Build a K-NN model with your own choice of k value, and evaluate the performance of your K-NN model. Does it have a higher or lower AUC than your decision tree model?
```{r}

mod_knn <- class::knn(cl = cancer_normalized_train$Class,
                  test = cancer_normalized_test[,1:9],
                  train = cancer_normalized_train[,1:9],
                  k = 3,
                  prob = TRUE)

roc_knn <- roc(cancer_normalized_test$Class, attributes(mod_knn)$prob)

auc(roc_knn)

```


### 7. Try several different k values, report the AUC of each one you tried. Also, report which k value gives you the highest AUC. Try using a for loop for this task.
```{r}
i = 1

mylist <- list()

for (i in 1:10){

    mod_knn <- class::knn(cl = cancer_normalized_train$Class,
                      test = cancer_normalized_test[,1:9],
                      train = cancer_normalized_train[,1:9],
                      k = i,
                      prob = TRUE)
    
    roc_knn <- roc(cancer_normalized_test$Class, attributes(mod_knn)$prob)
    
    name <- paste('knn = ',i,sep='')
    tmp <-list(auc(roc_knn))
    mylist[[name]] <-tmp
    
    
    cat("k = ",i, ", AUC = ",auc(roc_knn))
}

plot(unlist(mylist), main = "AUC vs k", xlab = "k",ylab = "AUC")

auc_knn<-max(unlist(mylist))

```


### 8. Build a naive bayes model, and evaluate its performance on the same testing data. Does it have higher or lower AUC than your best decision tree and k-NN models?
```{r}

nb_model <- naiveBayes(Class ~., data = cancer_train)

pred_nb_prob <- predict(nb_model, cancer_test, type = "raw")

cancer_test_roc_nb <-cancer_test %>%
  mutate(prob = pred_nb_prob[,1]) %>%
  arrange(desc(Class))%>%
  mutate(Class_malignant = ifelse(Class == 4,1,0))

roc_nb <- roc(response = cancer_test_roc_nb$Class_malignant,
              predictor = cancer_test_roc_nb$prob)

auc_nb <- auc(roc_nb)
auc_nb

```


### 9. Take your best model in terms of AUC, and plot the lift curve. What is the lift ratio at top 10% of cases with highest "malignant" probability as predicted by your model? Interpret the meaning of that lift ratio.
```{r}

paste("knn =", format(round(auc_knn, 4), nsmall = 4))
paste("NB = ",format(round(auc_nb, 4), nsmall = 4))
paste("decision_tree =", format(round(auc_tree, 4), nsmall = 4))



gain_lift(data = cancer_test_roc_nb, score = "prob", target = "Class_malignant")


```


### 10. Again take your best model in terms of AUC, and plot the ROC curve for class "malignant".
```{r}
plot (roc_nb, legacy.axes = T, asp=NA)
```

